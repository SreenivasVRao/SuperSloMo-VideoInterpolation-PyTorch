from layers import *
import torch.nn as nn
import torch.nn.functional as F
import torch
import logging

log = logging.getLogger(__name__)

class UNet(nn.Module):

    def __init__(self, in_channels, out_channels, batch_norm=False, verbose=False):
        super(UNet, self).__init__()
        self.batchNorm = batch_norm
        self.verbose = verbose
        self.build_model(in_channels, out_channels)

    def build_model(self, in_channels, out_channels):
        """

        :param in_channels: Number of channels for input tensor.
        :param out_channels: Number of channels for output tensor.
        :return:
        """

        # block 1

        self.conv1a = conv(in_planes=in_channels, out_planes=32, kernel_size=7, padding=3)
        self.conv1b = conv(in_planes=32, out_planes=32, kernel_size=7, padding=3)

        # block 2

        self.pool2 = avg_pool(kernel_size=2, stride=None, padding=0) # 1/2
        self.conv2a = conv(in_planes=32, out_planes=64, kernel_size=5, padding=2)
        self.conv2b = conv(in_planes=64, out_planes=64, kernel_size=5, padding=2)

        # block 3

        self.pool3 = avg_pool(kernel_size=2, stride=None, padding=0) # 1/4
        self.conv3a = conv(in_planes=64, out_planes=128,kernel_size=3)
        self.conv3b = conv(in_planes=128, out_planes=128,kernel_size=3)


        # block 4

        self.pool4 = avg_pool(kernel_size=2, stride=None, padding=0) # 1/8
        self.conv4a = conv(in_planes=128, out_planes=256,kernel_size=3)
        self.conv4b = conv(in_planes=256, out_planes=256, kernel_size=3)

        # block 5

        self.pool5 = avg_pool(kernel_size=2, stride=None, padding=0) # 1/16
        self.conv5a = conv(in_planes=256, out_planes=512, kernel_size=3)
        self.conv5b = conv(in_planes=512, out_planes=512, kernel_size=3)

        # block 6
        self.pool6 = avg_pool(kernel_size=2, stride=None, padding=0) # 1/32
        self.conv6a = conv(in_planes=512, out_planes=512, kernel_size=3)
        self.conv6b = conv(in_planes=512, out_planes=512, kernel_size=3)

        # block 7

        self.upsample7 = lambda x: F.upsample(x, size=(2 * x.shape[2], 2 * x.shape[3]),
                                              mode='bilinear')  # 2 x 2 upsampling
        # 1/16

        self.conv7a = conv(in_planes=1024, out_planes=512,kernel_size=3)
        self.conv7b = conv(in_planes=512, out_planes=512, kernel_size=3)


        # block 8

        self.upsample8 = lambda x: F.upsample(x, size=(2 * x.shape[2], 2 * x.shape[3]),
                                              mode='bilinear')  # 2 x 2 upsampling
        # 1/8

        self.conv8a = conv(in_planes=768, out_planes=256, kernel_size=3)
        self.conv8b = conv(in_planes=256, out_planes=256, kernel_size=3)


        # block 9

        self.upsample9 = lambda x: F.upsample(x, size=(2 * x.shape[2], 2 * x.shape[3]),
                                              mode='bilinear')  # 2 x 2 upsampling
        # 1/4

        self.conv9a = conv(in_planes=384, out_planes=128, kernel_size=3)
        self.conv9b = conv(in_planes=128, out_planes=128, kernel_size=3)

        # # block 10
        #
        self.upsample10 = lambda x: F.upsample(x, size=(2 * x.shape[2], 2 * x.shape[3]),
                                               mode='bilinear')  # 2 x 2 upsampling
        # 1/2

        self.conv10a = conv(in_planes=192, out_planes=64, kernel_size=3)
        self.conv10b = conv(in_planes=64, out_planes=64, kernel_size=3)

        # block 11

        self.upsample11 = lambda x: F.upsample(x, size=(2 * x.shape[2], 2 * x.shape[3]),
                                               mode='bilinear')  # 2 x 2 upsampling
        # 1

        self.conv11a = conv(in_planes=96, out_planes=32, kernel_size=3)
        self.conv11b = conv(in_planes=32, out_planes=out_channels, kernel_size=3)
        self.squash = nn.Sigmoid()

    def forward(self, input_tensor):
        """
        :param input_tensor: input: N,18, H, W,
        batch_size = N

        :return: output_tensor: N, 18, H, W, C
        interpolation result

        """
        if self.verbose:
            log.info("Input: " + str(input_tensor.shape))

        conv1a_out = self.conv1a(input_tensor)
        conv1b_out = self.conv1b(conv1a_out)

        if self.verbose:
            log.info("Output Block 1: "+str(conv1b_out.shape))

        pool2_out  = self.pool2(conv1b_out)
        conv2a_out = self.conv2a(pool2_out)
        conv2b_out = self.conv2b(conv2a_out)

        if self.verbose:
            log.info("Output Block 2: "+str(conv2b_out.shape))

        pool3_out  = self.pool3(conv2b_out)
        conv3a_out = self.conv3a(pool3_out)
        conv3b_out = self.conv3b(conv3a_out)

        if self.verbose:
            log.info("Output Block 3: "+str(conv3b_out.shape))

        pool4_out  = self.pool4(conv3b_out)
        conv4a_out = self.conv4a(pool4_out)
        conv4b_out = self.conv4b(conv4a_out)

        if self.verbose:
            log.info("Output Block 4: "+str(conv4b_out.shape))

        pool5_out  = self.pool5(conv4b_out)
        conv5a_out = self.conv5a(pool5_out)
        conv5b_out = self.conv5b(conv5a_out)

        if self.verbose:
            log.info("Output Block 5: "+str(conv5b_out.shape))

        pool6_out  = self.pool6(conv5b_out)
        conv6a_out = self.conv6a(pool6_out)
        conv6b_out = self.conv6b(conv6a_out)

        if self.verbose:
            log.info("Output Block 6: "+str(conv6b_out.shape))

        upsample7_out = self.upsample7(conv6b_out)
        input_7 = torch.cat([upsample7_out, conv5b_out], dim=1)
        conv7a_out = self.conv7a(input_7)
        conv7b_out = self.conv7b(conv7a_out)

        if self.verbose:
            log.info("Output Block 7: "+str(conv7b_out.shape))

        upsample8_out = self.upsample8(conv7b_out)
        input_8 = torch.cat([upsample8_out, conv4b_out], dim=1)
        conv8a_out = self.conv8a(input_8)
        conv8b_out = self.conv8b(conv8a_out)

        if self.verbose:
            log.info("Output Block 8: "+str(conv8b_out.shape))

        upsample9_out = self.upsample8(conv8b_out)
        input_9 = torch.cat([upsample9_out, conv3b_out], dim=1)
        conv9a_out = self.conv9a(input_9)
        conv9b_out = self.conv9b(conv9a_out)

        if self.verbose:
            log.info("Output Block 9: "+str(conv9b_out.shape))

        upsample10_out = self.upsample10(conv9b_out)
        input_10 = torch.cat([upsample10_out, conv2b_out], dim=1)
        conv10a_out = self.conv10a(input_10)
        conv10b_out = self.conv10b(conv10a_out)

        if self.verbose:
            log.info("Output Block 10: "+str(conv10b_out.shape))

        upsample11_out = self.upsample11(conv10b_out)
        input_11 = torch.cat([upsample11_out, conv1b_out], dim=1)
        conv11a_out = self.conv11a(input_11)
        conv11b_out = self.conv11b(conv11a_out)
        if self.verbose:
            log.info("Output Block 11: "+str(conv11b_out.shape))

        return conv11b_out

    def extract_outputs(self, output_tensor):
        """
        Extracts different elements in the output tensor.

        :param output_tensor: Output from the flow interpolation model.
        :return: The extract elements.
        """
        v_1t = output_tensor[:, 0, ...] # Visibility Map 1-> t
        dflow_t1 = output_tensor[:, 1:3, ...] # Residual of flow t->1
        dflow_t0 = output_tensor[:, 3:, ...] # Residual of flow t->0

        v_1t = v_1t[:, None, ...] # making dimensions compatible
        v_1t = self.squash(v_1t)

        v_0t = 1 - v_1t # Visibility Map 0->t

        return v_1t, dflow_t1, dflow_t0, v_0t

    def compute_output_image(self, image_tensor, input_tensor, output_tensor, t):
        """
        :param input_tensor: Input to flow interpolation model.
        :param output_tensor: Prediction from flow interpolation model
        :param t: Time step of interpolation (0 < t < 1)
        :return: I_t after enforcing constraints. B C H W
        """
        img_0 = image_tensor[:, :3, ...]
        img_1 = image_tensor[:, 3:, ...]

        est_flow_t1 = input_tensor[:, 6:8, ...] # Estimated flow t->1
        est_flow_t0 = input_tensor[:, 8:10, ...] # Estimated flow t->0

        pred_v_1t, pred_dflow_t1, pred_dflow_t0, pred_v_0t = self.extract_outputs(output_tensor)

        pred_flow_t1 = est_flow_t1 + pred_dflow_t1
        pred_flow_t0 = est_flow_t0 + pred_dflow_t0

        pred_img_0t = warp(img_0, -pred_flow_t0) # backward warping to produce img at time t
        pred_img_1t = warp(img_1, -pred_flow_t1) # backward warping to produce img at time t

        pred_img_0t = pred_v_0t * pred_img_0t # visibility map occlusion reasoning
        pred_img_1t = pred_v_1t * pred_img_1t # visibility map occlusion reasoning

        weighted_sum =(1 - t) * pred_img_0t  + t * pred_img_1t

        normalization_factor = (1 - t) * pred_v_0t + t * pred_v_1t # Z (refer to paper)

        pred_img_t = weighted_sum/normalization_factor

        return pred_img_t


def get_model(path, in_channels, out_channels, verbose=False):
    model = UNet(in_channels, out_channels, verbose=verbose)
    if path is not None:
        data = torch.load(path)
        if 'stage2_state_dict' in data.keys():
            model.load_state_dict(data['stage2_state_dict'])
        else:
            model.load_state_dict(data)
        log.info("Loaded weights for Flow Interpolator: "+str(path))
    else:
        log.info("Not loading weights for Flow Interpolator.")
    return model



if __name__=='__main__':
    logging.basicConfig(filename="test.log", level=logging.INFO)

    model = get_model(path=None, in_channels=16, out_channels=5, verbose=True)
    model = model.cuda()

    input_sample = Variable(torch.randn([1, 16, 320, 640])).cuda()
    output_sample = model(input_sample)
    image_tensor = Variable(torch.randn([1, 6, 320, 640])).cuda()

    print model.compute_output_image(image_tensor, input_sample, output_sample, t=0.5).shape

##########################################
# // And all you touch and all you see,//#
# // Is all your life will ever be!    //#
##########################################
