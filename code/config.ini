[PROJECT]
DIR=/home/sreenivasv/CS701/SuperSloMo-PyTorch/

[ADOBE_DATA]
TRAINPATHS=/mnt/nfs/work1/elm/hzjiang/Data/VideoInterpolation/Adobe240fps/train_clips_video_interp.txt
VALPATHS=/mnt/nfs/work1/elm/hzjiang/Data/VideoInterpolation/Adobe240fps/val_clips_video_interp.txt
H = 320
W = 640

[TRAIN]
BATCH_SIZE=12
N_EPOCHS=500
LEARNING_RATE=0.0001
LR_PERIOD=200
SAVE_EVERY=50
LR_DECAY=0.1
T_INTERP=0.5

LAMBDA_R=1
; reconstruction loss weighting

LAMBDA_W=0.17
; warp loss weighting

LAMBDA_S=0
; smoothness loss weighting

LAMBDA_P=0.02
; perceptual loss weighting

[VAL]
BATCH_SIZE=12


[STAGE1]
MODEL=UNETC
; PWC or UNETA or UNETC
WEIGHTS=
LOADPREV=FALSE
FREEZE=FALSE

[STAGE2]
MODEL=UNETC
; UNETA or UNETC
WEIGHTS=
LOADPREV=FALSE
FREEZE=FALSE
CROSS_SKIP=TRUE
; Skip connections from stage1 encoders to stage2.

[MISC]
N_WORKERS=24
T_SAMPLE=FIXED

[SEED]
VALUE=42

[MESSAGE]
INFO= BATCH_SIZE=12, T Fixed. Multi GPUs. 352 x 352. 20 channels input to stage 2. Warp loss on stage 1 only.
